\documentclass[12pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{caption}
\usepackage{subcaption}

% Page geometry
\geometry{margin=1in}

% Code listing style
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{green!60!black},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    frame=single,
    breaklines=true
}

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
    citecolor=blue
}

\title{
    \textbf{Illuminated Drone Show Simulation} \\
    \large Numerical Programming Final Project \\
    \vspace{0.5cm}
    \normalsize NP 2025
}

\author{
    Ramaz Botchorishvili \\
    \textit{Kutaisi International University} \\
    \texttt{r.botchorishvili@kiu.edu.ge}
}

\date{January 2026}

\begin{document}

\maketitle

\begin{abstract}
This report presents a comprehensive simulation of an illuminated drone light show using numerical methods. The project models drone swarm dynamics as an Initial Value Problem (IVP) consisting of coupled ordinary differential equations governing position and velocity. The system incorporates spring-damper dynamics for target tracking, velocity saturation for realistic motion constraints, and repulsive forces for collision avoidance. The IVP is solved using the 4th-order Runge-Kutta (RK4) method, providing $O(h^4)$ global accuracy. The simulation demonstrates three distinct phases: static-to-static transitions forming handwritten text, image-based shape formation, and dynamic tracking of animated GIF frames. All core numerical algorithms are implemented from first principles using only NumPy for array operations, demonstrating mastery of numerical methods including spatial hashing for efficient neighbor queries, greedy assignment for target matching, and complete image processing pipelines for edge detection.
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
\section{Introduction}
%==============================================================================

\subsection{Background}

Illuminated drone shows have emerged as a spectacular form of entertainment and artistic expression, replacing traditional fireworks displays at major events worldwide. Companies like Intel and EHang have demonstrated swarms of thousands of synchronized drones forming complex three-dimensional shapes in the night sky. These shows require precise coordination algorithms to ensure smooth transitions between formations while maintaining safe separation distances between aircraft.

The mathematical foundation of drone swarm coordination lies in numerical methods for solving differential equations, optimization algorithms for path planning, and real-time control systems. This project applies concepts from numerical programming to simulate such a drone light show in a 2D environment.

\subsection{Project Goals}

The primary objectives of this project are:

\begin{enumerate}
    \item \textbf{Model drone dynamics} as an Initial Value Problem using coupled ODEs for position and velocity
    \item \textbf{Implement RK4 integration} from scratch to solve the IVP with high accuracy
    \item \textbf{Design collision avoidance} using repulsive force fields between nearby drones
    \item \textbf{Extract target formations} from images using edge detection algorithms
    \item \textbf{Demonstrate three operational modes}: static-to-static, static-to-image, and dynamic tracking
\end{enumerate}

\subsection{Three Subtasks}

The simulation consists of three distinct phases (subtasks):

\begin{description}
    \item[Subtask 1:] Transition from initial grid formation to a handwritten name
    \item[Subtask 2:] Transition from the name to a greeting image (``Happy New Year'')
    \item[Subtask 3:] Dynamic tracking of a moving target extracted from an animated GIF
\end{description}

%==============================================================================
\section{Mathematical Model}
%==============================================================================

\subsection{Initial Value Problem Formulation}

The motion of each drone is governed by a second-order ODE system, reformulated as a first-order IVP. Let $\mathbf{x}_i(t) \in \mathbb{R}^2$ denote the position and $\mathbf{v}_i(t) \in \mathbb{R}^2$ the velocity of drone $i$ at time $t$.

\subsubsection{Velocity Equation with Saturation}

The position evolves according to velocity with a maximum speed constraint:

\begin{equation}
    \frac{d\mathbf{x}_i}{dt} = \mathbf{v}_i \cdot \min\left(1, \frac{v_{\max}}{|\mathbf{v}_i|}\right)
    \label{eq:position}
\end{equation}

This ensures that regardless of the computed velocity, the actual displacement never exceeds $v_{\max}$ per unit time.

\subsubsection{Acceleration Equation (Spring-Damper with Repulsion)}

The velocity evolves according to a combination of forces:

\begin{equation}
    \frac{d\mathbf{v}_i}{dt} = \frac{1}{m}\left[k_p(\mathbf{T}_i - \mathbf{x}_i) + \mathbf{f}_{rep,i} - k_d\mathbf{v}_i\right]
    \label{eq:velocity}
\end{equation}

where:
\begin{itemize}
    \item $m$ is the drone mass
    \item $k_p(\mathbf{T}_i - \mathbf{x}_i)$ is the spring force pulling toward target $\mathbf{T}_i$
    \item $k_d\mathbf{v}_i$ is the damping force (viscous friction)
    \item $\mathbf{f}_{rep,i}$ is the repulsive force from nearby drones
\end{itemize}

\subsection{Repulsive Force Model}

To prevent collisions, drones within a safety radius $R_{safe}$ exert repulsive forces on each other:

\begin{equation}
    \mathbf{f}_{rep,i} = \sum_{j \neq i, |\mathbf{x}_i - \mathbf{x}_j| < R_{safe}} k_{rep} \cdot \frac{\mathbf{x}_i - \mathbf{x}_j}{|\mathbf{x}_i - \mathbf{x}_j|^3}
    \label{eq:repulsion}
\end{equation}

This inverse-square law creates strong repulsion at close range that diminishes rapidly with distance, similar to electrostatic repulsion between like charges.

\subsection{Model Parameters}

Table \ref{tab:parameters} summarizes the physical parameters used in the simulation.

\begin{table}[H]
\centering
\caption{Simulation Parameters}
\label{tab:parameters}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{Symbol} & \textbf{Parameter} & \textbf{Value} & \textbf{Unit} \\
\midrule
$m$ & Drone mass & 1.0 & kg \\
$k_p$ & Spring constant (position gain) & 25.0 & N/m \\
$k_d$ & Damping coefficient & 12.0 & N·s/m \\
$k_{rep}$ & Repulsion strength & 50.0 & N·m² \\
$R_{safe}$ & Safety radius & 4.0 & m \\
$v_{\max}$ & Maximum velocity & 100.0 & m/s \\
$\Delta t$ & Time step & 0.05 & s \\
$n$ & Number of drones & 1200 & -- \\
\bottomrule
\end{tabular}
\end{table}

%==============================================================================
\section{Numerical Methods}
%==============================================================================

\subsection{4th-Order Runge-Kutta Integration}

The IVP system (Equations \ref{eq:position} and \ref{eq:velocity}) is solved using the classical 4th-order Runge-Kutta method (RK4). For a general ODE $\frac{dy}{dt} = f(t, y)$, RK4 computes:

\begin{align}
    k_1 &= f(t_n, y_n) \\
    k_2 &= f\left(t_n + \frac{h}{2}, y_n + \frac{h}{2}k_1\right) \\
    k_3 &= f\left(t_n + \frac{h}{2}, y_n + \frac{h}{2}k_2\right) \\
    k_4 &= f(t_n + h, y_n + hk_3) \\
    y_{n+1} &= y_n + \frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)
    \label{eq:rk4}
\end{align}

\subsubsection{Error Analysis}

RK4 has a local truncation error of $O(h^5)$ and a global error of $O(h^4)$. For our time step $\Delta t = 0.05$s, this provides excellent accuracy while maintaining computational efficiency for 1200 drones simulated over thousands of frames.

\subsubsection{Implementation}

The coupled system is integrated simultaneously:

\begin{algorithm}[H]
\caption{RK4 Integration Step}
\begin{algorithmic}[1]
\Function{Step}{$\mathbf{x}, \mathbf{v}, \mathbf{T}$}
    \State $k_{1x}, k_{1v} \gets \text{deriv}(\mathbf{x}, \mathbf{v})$
    \State $k_{2x}, k_{2v} \gets \text{deriv}(\mathbf{x} + \frac{\Delta t}{2}k_{1x}, \mathbf{v} + \frac{\Delta t}{2}k_{1v})$
    \State $k_{3x}, k_{3v} \gets \text{deriv}(\mathbf{x} + \frac{\Delta t}{2}k_{2x}, \mathbf{v} + \frac{\Delta t}{2}k_{2v})$
    \State $k_{4x}, k_{4v} \gets \text{deriv}(\mathbf{x} + \Delta t \cdot k_{3x}, \mathbf{v} + \Delta t \cdot k_{3v})$
    \State $\mathbf{x} \gets \mathbf{x} + \frac{\Delta t}{6}(k_{1x} + 2k_{2x} + 2k_{3x} + k_{4x})$
    \State $\mathbf{v} \gets \mathbf{v} + \frac{\Delta t}{6}(k_{1v} + 2k_{2v} + 2k_{3v} + k_{4v})$
    \State \Return $\mathbf{x}, \mathbf{v}$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Spatial Hashing for Collision Detection}

Naive collision detection requires $O(n^2)$ distance calculations. We implement spatial hashing to reduce this to $O(n)$ average case.

\subsubsection{Hash Function}

The 2D space is discretized into grid cells of size $c = R_{safe}$:

\begin{equation}
    h(x, y) = \left(\left\lfloor \frac{x}{c} \right\rfloor, \left\lfloor \frac{y}{c} \right\rfloor\right)
    \label{eq:hash}
\end{equation}

\subsubsection{Neighbor Query Algorithm}

For each drone, we only check the 3×3 neighborhood of cells:

\begin{algorithm}[H]
\caption{Find Neighbor Pairs using Spatial Hashing}
\begin{algorithmic}[1]
\Function{FindNeighborPairs}{positions, radius}
    \State cells $\gets$ BuildSpatialHashGrid(positions, radius)
    \State pairs $\gets$ [ ]
    \For{each drone $i$}
        \State $(c_x, c_y) \gets$ cell of drone $i$
        \For{$dx, dy \in \{-1, 0, 1\}$}
            \For{each drone $j$ in cell $(c_x + dx, c_y + dy)$}
                \If{$j > i$ and $|\mathbf{x}_i - \mathbf{x}_j| < $ radius}
                    \State pairs.append$(i, j)$
                \EndIf
            \EndFor
        \EndFor
    \EndFor
    \State \Return pairs
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Greedy Assignment Algorithm}

To assign drones to target positions, we use a greedy algorithm:

\begin{equation}
    \text{For each drone } i: \quad j^* = \arg\min_{j \text{ unassigned}} \|\mathbf{x}_i - \mathbf{T}_j\|
\end{equation}

This provides $O(n^2)$ complexity compared to $O(n^3)$ for the optimal Hungarian algorithm, with acceptable results for our application.

%==============================================================================
\section{Image Processing}
%==============================================================================

Target formations are extracted from input images using edge detection. All algorithms are implemented from mathematical first principles.

\subsection{Gaussian Blur}

Noise reduction is performed using 2D Gaussian convolution:

\begin{equation}
    G(x, y) = \frac{1}{2\pi\sigma^2} \exp\left(-\frac{x^2 + y^2}{2\sigma^2}\right)
    \label{eq:gaussian}
\end{equation}

The convolution operation:

\begin{equation}
    (f * G)(x, y) = \sum_i \sum_j f(i, j) \cdot G(x-i, y-j)
\end{equation}

\subsection{Sobel Edge Detection}

Gradient computation uses Sobel operators:

\begin{equation}
    G_x = \begin{bmatrix} -1 & 0 & 1 \\ -2 & 0 & 2 \\ -1 & 0 & 1 \end{bmatrix}, \quad
    G_y = \begin{bmatrix} -1 & -2 & -1 \\ 0 & 0 & 0 \\ 1 & 2 & 1 \end{bmatrix}
\end{equation}

Gradient magnitude and direction:

\begin{equation}
    |\nabla I| = \sqrt{G_x^2 + G_y^2}, \quad \theta = \arctan\left(\frac{G_y}{G_x}\right)
\end{equation}

\subsection{Canny Edge Detection}

The complete Canny algorithm consists of four stages:

\begin{enumerate}
    \item \textbf{Gaussian Blur}: Reduce noise using Equation \ref{eq:gaussian}
    \item \textbf{Gradient Computation}: Apply Sobel operators
    \item \textbf{Non-Maximum Suppression}: Thin edges by keeping only local maxima in gradient direction
    \item \textbf{Hysteresis Thresholding}: Connect edges using dual thresholds (low=50, high=150)
\end{enumerate}

%==============================================================================
\section{Implementation}
%==============================================================================

\subsection{Software Architecture}

The simulation is implemented in Python 3.12 with the following structure:

\begin{itemize}
    \item \texttt{drone\_show\_math.py}: Pure mathematical implementation (692 lines)
    \item \texttt{drone\_show.py}: Optimized version using scipy for comparison
    \item \texttt{MATH\_IMPLEMENTATION\_NOTES.md}: Documentation of algorithms
\end{itemize}

\subsection{Dependencies}

\begin{itemize}
    \item \textbf{NumPy}: Array operations and vectorized mathematics
    \item \textbf{OpenCV}: Image/video I/O only (no algorithmic functions)
    \item \textbf{Pillow}: GIF frame extraction
\end{itemize}

\subsection{Three Subtasks Implementation}

\subsubsection{Subtask 1: Initial $\rightarrow$ Handwritten Name}

Drones start in a uniform grid and transition to positions forming a handwritten name. Target points are extracted from \texttt{handwritten\_name.png} using edge detection.

\subsubsection{Subtask 2: Name $\rightarrow$ Greeting Image}

From the name formation, drones smoothly transition to form the greeting ``Happy New Year'' extracted from \texttt{greeting.png}.

\subsubsection{Subtask 3: Dynamic GIF Tracking}

Drones track a moving target extracted from an animated GIF (41 frames). The assignment is updated every 6 physics steps to balance responsiveness and smoothness.

%==============================================================================
\section{Results}
%==============================================================================

\subsection{Output Summary}

The simulation produces the following outputs:

\begin{table}[H]
\centering
\caption{Simulation Output Statistics}
\label{tab:results}
\begin{tabular}{@{}lrrr@{}}
\toprule
\textbf{Phase} & \textbf{Frames} & \textbf{Duration (s)} & \textbf{Description} \\
\midrule
Phase 1 & 110 & 3.7 & Grid $\rightarrow$ Handwritten Name \\
Phase 2 & 110 & 3.7 & Name $\rightarrow$ Greeting \\
Phase 3 & 246 & 8.2 & Dynamic GIF Tracking \\
\midrule
\textbf{Total} & \textbf{466} & \textbf{15.5} & Combined simulation \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Video Outputs}

Eight video files are generated:

\begin{itemize}
    \item \texttt{drone\_show\_math\_phase1.mp4}: Subtask 1 only
    \item \texttt{drone\_show\_math\_phase2.mp4}: Subtask 2 only
    \item \texttt{drone\_show\_math\_phase3.mp4}: Subtask 3 only
    \item \texttt{drone\_show\_math\_combined.mp4}: All phases combined
    \item (Plus 4 equivalent files from the optimized implementation)
\end{itemize}

\subsection{Performance}

\begin{itemize}
    \item \textbf{Drones}: 1200 simultaneous particles
    \item \textbf{Frame rate}: 30 FPS output
    \item \textbf{Runtime}: Approximately 2 minutes for full simulation
    \item \textbf{Collision-free}: Zero collisions observed (repulsive forces effective)
\end{itemize}

%==============================================================================
\section{Conclusion}
%==============================================================================

This project successfully demonstrates the application of numerical methods to simulate an illuminated drone light show. Key achievements include:

\begin{enumerate}
    \item \textbf{IVP Formulation}: Modeled drone dynamics as coupled ODEs with spring-damper physics and velocity saturation
    
    \item \textbf{RK4 Implementation}: Solved the IVP using 4th-order Runge-Kutta integration implemented from first principles, achieving $O(h^4)$ accuracy
    
    \item \textbf{Collision Avoidance}: Implemented inverse-square repulsive forces with spatial hashing for $O(n)$ neighbor queries
    
    \item \textbf{Image Processing}: Built complete edge detection pipeline including Gaussian blur, Sobel gradients, and Canny algorithm
    
    \item \textbf{Pure Mathematical Implementation}: All core algorithms implemented using only NumPy array operations, demonstrating understanding of the underlying mathematics
    
    \item \textbf{Three Operational Modes}: Successfully demonstrated static-to-static transitions and dynamic target tracking
\end{enumerate}

The simulation produces smooth, collision-free transitions between formations with 1200 drones over a 15-second video, validating the effectiveness of the chosen numerical methods and physical model.

\subsection{Future Work}

Potential extensions include:
\begin{itemize}
    \item 3D extension with perspective projection
    \item Optimal assignment using the Hungarian algorithm
    \item Real-time interactive control
    \item Hardware deployment on actual drone swarms
\end{itemize}

%==============================================================================
\section*{References}
%==============================================================================

\begin{enumerate}
    \item Burden, R.L., Faires, J.D. (2015). \textit{Numerical Analysis}, 10th Edition. Cengage Learning.
    \item Canny, J. (1986). A Computational Approach to Edge Detection. \textit{IEEE TPAMI}, 8(6), 679-698.
    \item Reynolds, C.W. (1987). Flocks, Herds, and Schools: A Distributed Behavioral Model. \textit{SIGGRAPH '87}.
\end{enumerate}

%==============================================================================
\appendix
\section{Source Code Repository}
%==============================================================================

The complete source code is available at:

\url{https://github.com/devichikovani/np-final-project}

\end{document}
